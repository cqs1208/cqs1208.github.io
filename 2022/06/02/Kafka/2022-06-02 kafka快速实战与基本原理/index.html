<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="kafka">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka快速实战与基本原理">
<meta property="og:url" content="http://example.com/2022/06/02/Kafka/2022-06-02%20kafka%E5%BF%AB%E9%80%9F%E5%AE%9E%E6%88%98%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="kafka">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base01.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base02.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base03.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base04.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base05.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base06.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base07.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base08.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base09.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base10.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base11.png">
<meta property="og:image" content="http://example.com/images/Kafka/Kafka_base12.png">
<meta property="article:published_time" content="2022-06-02T02:58:24.041Z">
<meta property="article:modified_time" content="2022-06-07T02:03:22.223Z">
<meta property="article:author" content="QingSong">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/Kafka/Kafka_base01.png">

<link rel="canonical" href="http://example.com/2022/06/02/Kafka/2022-06-02%20kafka%E5%BF%AB%E9%80%9F%E5%AE%9E%E6%88%98%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>kafka快速实战与基本原理 | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">点滴积累 豁达处之</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/02/Kafka/2022-06-02%20kafka%E5%BF%AB%E9%80%9F%E5%AE%9E%E6%88%98%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar/avatar.png">
      <meta itemprop="name" content="QingSong">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          kafka快速实战与基本原理
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-02 10:58:24" itemprop="dateCreated datePublished" datetime="2022-06-02T10:58:24+08:00">2022-06-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-07 10:03:22" itemprop="dateModified" datetime="2022-06-07T10:03:22+08:00">2022-06-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          
            <div class="post-description">kafka</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、Storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源 项目。</p>
<a id="more"></a> 

<h2 id="Kafka的使用场景"><a href="#Kafka的使用场景" class="headerlink" title="Kafka的使用场景"></a><strong>Kafka的使用场景</strong></h2><ul>
<li>日志收集：一个公司可以用Kafka收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。</li>
<li>消息系统：解耦和生产者和消费者、缓存消息等。</li>
<li>用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。</li>
<li>运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。</li>
</ul>
<p><img src="/images/Kafka/Kafka_base01.png" alt="Kafka_base01"></p>
<h2 id="Kafka基本概念"><a href="#Kafka基本概念" class="headerlink" title="Kafka基本概念"></a><strong>Kafka基本概念</strong></h2><p>kafka是一个分布式的，分区的消息(官方称之为commit log)服务。它提供一个消息系统应该具备的功能，但是确有着独特的设计。可以这样来说，Kafka借鉴了JMS规范的思想，但是确并<strong>没有完全遵循JMS规范。</strong></p>
<p>首先，让我们来看一下基础的消息(Message)相关术语：</p>
<table>
<thead>
<tr>
<th><strong>名称</strong></th>
<th><strong>解释</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Broker</td>
<td>消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群</td>
</tr>
<tr>
<td>Topic</td>
<td>Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic</td>
</tr>
<tr>
<td>Producer</td>
<td>消息生产者，向Broker发送消息的客户端</td>
</tr>
<tr>
<td>Consumer</td>
<td>消息消费者，从Broker读取消息的客户端</td>
</tr>
<tr>
<td>ConsumerGroup</td>
<td>每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个Consumer Group中只能有一个Consumer能够消费该消息</td>
</tr>
<tr>
<td>Partition</td>
<td>物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的</td>
</tr>
</tbody></table>
<p>因此，从一个较高的层面上来看，producer通过网络发送消息到Kafka集群，然后consumer来进行消费，如下图：</p>
<p><img src="/images/Kafka/Kafka_base02.png" alt="Kafka_base02"></p>
<p>服务端(brokers)和客户端(producer、consumer)之间通信通过<strong>TCP协议</strong>来完成。</p>
<h2 id="kafka基本使用"><a href="#kafka基本使用" class="headerlink" title="kafka基本使用"></a><strong>kafka基本使用</strong></h2><p>kafka依赖zookeeper，所以需要先安装zookeeper</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">wget https:<span class="comment">//archive.apache.org/dist/zookeeper/zookeeper-3.5.8/apache-zookeeper-3.5.8-bin.tar.gz</span></span><br><span class="line">tar -zxvf apache-zookeeper-<span class="number">3.5</span>.<span class="number">8</span>-bin.tar.gz</span><br><span class="line">cd  apache-zookeeper-<span class="number">3.5</span>.<span class="number">8</span>-bin</span><br><span class="line">cp conf/zoo_sample.cfg conf/zoo.cfg</span><br><span class="line"></span><br><span class="line"># 启动zookeeper</span><br><span class="line">bin/zkServer.sh start</span><br><span class="line">bin/zkCli.sh </span><br><span class="line">ls /			#查看zk的根目录相关节点</span><br></pre></td></tr></table></figure>

<h3 id="第一步：下载安装包"><a href="#第一步：下载安装包" class="headerlink" title="第一步：下载安装包"></a><strong>第一步：下载安装包</strong></h3><p>下载2.4.1 release版本，并解压：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> wget https:<span class="comment">//archive.apache.org/dist/kafka/2.4.1/kafka_2.11-2.4.1.tgz  # 2.11是scala的版本，2.4.1是kafka的版本 </span></span><br><span class="line">tar -xzf kafka_2.<span class="number">11</span>-<span class="number">2.4</span>.<span class="number">1.</span>tgz cd kafka_2.<span class="number">11</span>-<span class="number">2.4</span>.<span class="number">1</span>  </span><br></pre></td></tr></table></figure>



<h3 id="第二步：修改配置"><a href="#第二步：修改配置" class="headerlink" title="第二步：修改配置"></a><strong>第二步：修改配置</strong></h3><p>修改配置文件config/server.properties:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#broker.id属性在kafka集群中必须要是唯一</span><br><span class="line">broker.id=<span class="number">0</span></span><br><span class="line">#kafka部署的机器ip和提供服务的端口号</span><br><span class="line">#listeners=PLAINTEXT://192.168.65.60:9092  </span><br><span class="line">listeners=PLAINTEXT:<span class="comment">//:9094</span></span><br><span class="line">advertised.listeners=PLAINTEXT:<span class="comment">//120.27.71.186:9092</span></span><br><span class="line">#kafka的消息存储文件</span><br><span class="line">log.dir=/usr/local/data/kafka-logs</span><br><span class="line">#kafka连接zookeeper的地址</span><br><span class="line">zookeeper.connect=<span class="number">120.27</span>.<span class="number">71.186</span>:<span class="number">2181</span></span><br></pre></td></tr></table></figure>



<h3 id="第三步：启动服务"><a href="#第三步：启动服务" class="headerlink" title="第三步：启动服务"></a><strong>第三步：启动服务</strong></h3><p>现在来启动kafka服务：</p>
<p>启动脚本语法：kafka-server-start.sh [-daemon] server.properties</p>
<p>可以看到，server.properties的配置路径是一个强制的参数，-daemon表示以后台进程运行，否则ssh客户端退出后，就会停止服务。(注意，在启动kafka时会使用linux主机名关联的ip地址，所以需要把主机名和linux的ip映射配置到本地host里，用vim /etc/hosts)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 启动kafka，运行日志在logs目录的server.log文件里</span><br><span class="line">bin/kafka-server-start.sh -daemon config/server.properties   #后台启动，不会打印日志到控制台</span><br><span class="line">或者用</span><br><span class="line">bin/kafka-server-start.sh config/server.properties &amp;</span><br><span class="line"></span><br><span class="line"># 我们进入zookeeper目录通过zookeeper客户端查看下zookeeper的目录树</span><br><span class="line">bin/zkCli.sh </span><br><span class="line">ls /		#查看zk的根目录kafka相关节点</span><br><span class="line">ls /brokers/ids	#查看kafka节点</span><br><span class="line"></span><br><span class="line"># 停止kafka</span><br><span class="line">bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure>

<p><strong>server.properties核心配置详解：</strong></p>
<table>
<thead>
<tr>
<th><strong>Property</strong></th>
<th><strong>Default</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody><tr>
<td>broker.id</td>
<td>0</td>
<td>每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯一的即可。</td>
</tr>
<tr>
<td>log.dirs</td>
<td>/tmp/kafka-logs</td>
<td>kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最少partitions的路径下进行。</td>
</tr>
<tr>
<td>listeners</td>
<td>PLAINTEXT://192.168.65.60:9092</td>
<td>server接受客户端连接的端口，ip配置kafka本机ip即可</td>
</tr>
<tr>
<td>zookeeper.connect</td>
<td>localhost:2181</td>
<td>zooKeeper连接字符串的格式为：hostname:port，此处hostname和port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果是集群，连接方式为 hostname1:port1, hostname2:port2, hostname3:port3</td>
</tr>
<tr>
<td>log.retention.hours</td>
<td>168</td>
<td>每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样。</td>
</tr>
<tr>
<td>num.partitions</td>
<td>1</td>
<td>创建topic的默认分区数</td>
</tr>
<tr>
<td>default.replication.factor</td>
<td>1</td>
<td>自动创建topic的默认副本数量，建议设置为大于等于2</td>
</tr>
<tr>
<td>min.insync.replicas</td>
<td>1</td>
<td>当producer设置acks为-1时，min.insync.replicas指定replicas的最小数目（必须确认每一个repica的写数据都是成功的），如果这个数目没有达到，producer发送消息会产生异常</td>
</tr>
<tr>
<td>delete.topic.enable</td>
<td>false</td>
<td>是否允许删除主题</td>
</tr>
</tbody></table>
<h3 id="第四步：创建主题"><a href="#第四步：创建主题" class="headerlink" title="第四步：创建主题"></a><strong>第四步：创建主题</strong></h3><p>现在我们来创建一个名字为“test”的Topic，这个topic只有一个partition，并且备份因子也设置为1：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper <span class="number">120.27</span>.<span class="number">71.186</span>:<span class="number">2181</span> --replication-factor <span class="number">1</span> --partitions <span class="number">1</span> --topic test</span><br></pre></td></tr></table></figure>

<p>现在我们可以通过以下命令来查看kafka中目前存在的topic</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --zookeeper <span class="number">120.27</span>.<span class="number">71.186</span>:<span class="number">2181</span>      </span><br></pre></td></tr></table></figure>

<p>除了我们通过手工的方式创建Topic，当producer发布一个消息到某个指定的Topic，这个Topic如果不存在，就自动创建。  </p>
<p><strong>删除主题</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --delete --topic test --zookeeper <span class="number">120.27</span>.<span class="number">71.186</span>:<span class="number">2181</span> </span><br></pre></td></tr></table></figure>

<h3 id="第五步：发送消息"><a href="#第五步：发送消息" class="headerlink" title="第五步：发送消息"></a><strong>第五步：发送消息</strong></h3><p>kafka自带了一个producer命令客户端，可以从本地文件中读取内容，或者我们也可以以命令行中直接输入内容，并将这些内容以消息的形式发送到kafka集群中。在默认情况下，每一个行会被当做成一个独立的消息。</p>
<p>首先我们要运行发布消息的脚本，然后在命令中输入要发送的消息的内容：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list <span class="number">120.27</span>.<span class="number">71.186</span>:<span class="number">9092</span> --topic test </span><br><span class="line">&gt;<span class="keyword">this</span> is a msg</span><br><span class="line">&gt;<span class="keyword">this</span> is a another msg </span><br></pre></td></tr></table></figure>

<h3 id="第六步：消费消息"><a href="#第六步：消费消息" class="headerlink" title="第六步：消费消息"></a><strong>第六步：消费消息</strong></h3><p>对于consumer，kafka同样也携带了一个命令行客户端，会将获取到内容在命令中进行输出，<strong>默认是消费最新的消息</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server <span class="number">120.27</span>.<span class="number">71.186</span>:<span class="number">9092</span> --topic test   </span><br></pre></td></tr></table></figure>

<p>如果想要消费之前的消息可以通过–from-beginning参数指定，如下命令：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server <span class="number">120.27</span>.<span class="number">71.186</span>:<span class="number">9092</span> --from-beginning --topic test </span><br></pre></td></tr></table></figure>

<p>如果你是通过不同的终端窗口来运行以上的命令，你将会看到在producer终端输入的内容，很快就会在consumer的终端窗口上显示出来。</p>
<p>以上所有的命令都有一些附加的选项；当我们不携带任何参数运行命令的时候，将会显示出这个命令的详细用法。</p>
<p><strong>消费多主题</strong>                </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server <span class="number">120.27</span>.<span class="number">71.186</span>:<span class="number">9092</span> --whitelist <span class="string">&quot;test|test-2&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>单播消费</strong></p>
<p>一条消息只能被某一个消费者消费的模式，类似queue模式，只需让所有消费者在同一个消费组里即可</p>
<p>分别在两个客户端执行如下消费命令，然后往主题里发送消息，结果只有一个客户端能收到消息</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server <span class="number">120.27</span>.<span class="number">71.186</span>:<span class="number">9092</span>  --consumer-property group.id=testGroup --topic test </span><br></pre></td></tr></table></figure>

<p><strong>多播消费</strong></p>
<p>一条消息能被多个消费者消费的模式，类似publish-subscribe模式费，针对Kafka同一条消息只能被同一个消费组下的某一个消费者消费的特性，要实现多播只要保证这些消费者属于不同的消费组即可。我们再增加一个消费者，该消费者属于testGroup-2消费组，结果两个客户端都能收到消息            </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-consumer.sh --bootstrap-server 120.27.71.186:9092 --consumer-property group.id&#x3D;testGroup-2 --topic test </span><br></pre></td></tr></table></figure>

<p><strong>查看消费组名</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-consumer-groups.sh --bootstrap-server 120.27.71.186:9092 --list </span><br></pre></td></tr></table></figure>

<p><strong>查看消费组的消费偏移量</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-consumer-groups.sh --bootstrap-server 120.27.71.186:9092 --describe --group testGroup</span><br></pre></td></tr></table></figure>

<p><img src="/images/Kafka/Kafka_base03.png" alt="Kafka_base03"></p>
<p><strong>current-offset：</strong>当前消费组的已消费偏移量</p>
<p><strong>log-end-offset：</strong>主题对应分区消息的结束偏移量(HW)</p>
<p><strong>lag：</strong>当前消费组未消费的消息数</p>
<h2 id="主题Topic和消息日志Log"><a href="#主题Topic和消息日志Log" class="headerlink" title="主题Topic和消息日志Log"></a><strong>主题Topic和消息日志Log</strong></h2><p><strong>可以理解Topic是一个类别的名称，同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件:</strong></p>
<p><img src="/images/Kafka/Kafka_base04.png" alt="Kafka_base04"></p>
<p>Partition是一个<strong>有序的message序列</strong>，这些message按顺序添加到一个叫做<strong>commit log的文件</strong>中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message。 </p>
<p><strong>每个partition，都对应一个commit log文件</strong>。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的。</p>
<p>kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响。</p>
<p><strong>每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的</strong>。在kafka中，<strong>消费offset由consumer自己来维护</strong>；一般情况下我们按照顺序逐条消费commit log中的消息，当然我可以通过指定offset来重复消费某些消息，或者跳过某些消息。</p>
<p>这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset。</p>
<p><strong>创建多个分区的主题：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --create --zookeeper 120.27.71.186:2181 --replication-factor 1 --partitions 2 --topic test1</span><br></pre></td></tr></table></figure>

<p><strong>查看下topic的情况</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --describe --zookeeper 120.27.71.186:2181 --topic test1</span><br></pre></td></tr></table></figure>

<p><img src="/images/Kafka/Kafka_base05.png" alt="Kafka_base05"></p>
<p>以下是输出内容的解释，第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息。</p>
<ul>
<li>leader节点负责给定partition的所有读写请求。</li>
<li>replicas 表示某个partition在哪几个broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出。</li>
<li>isr 是replicas的一个子集，它只列出当前还存活着的，并且<strong>已同步备份</strong>了该partition的节点。</li>
</ul>
<p>我们可以运行相同的命令查看之前创建的名称为”test“的topic</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --describe --zookeeper 120.27.71.186:2181 --topic test </span><br></pre></td></tr></table></figure>

<p>之前设置了topic的partition数量为1，备份因子为1，因此显示就如上所示了。 </p>
<p>可以进入kafka的数据文件存储目录查看test和test1主题的消息日志文件：</p>
<p><img src="/images/Kafka/Kafka_base06.png" alt="Kafka_base06"></p>
<p>消息日志文件主要存放在分区文件夹里的以log结尾的日志文件里，如下是test1主题对应的分区0的消息日志：</p>
<p><img src="/images/Kafka/Kafka_base07.png" alt="Kafka_base07"></p>
<p>当然我们也可以通过如下命令**增加topic的分区数量(目前kafka不支持减少分区)**：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh -alter --partitions 3 --zookeeper 120.27.71.186:2181 --topic test</span><br></pre></td></tr></table></figure>



<p><strong>可以这么来理解Topic，Partition和Broker</strong></p>
<p>一个topic，代表逻辑上的一个业务数据集，比如按数据库里不同表的数据操作消息区分放入不同topic，订单相关操作消息放入订单topic，用户相关操作消息放入用户topic，对于大型网站来说，后端数据都是海量的，订单消息很可能是非常巨量的，比如有几百个G甚至达到TB级别，如果把这么多数据都放在一台机器上可定会有容量限制问题，那么就可以在topic内部划分多个partition来分片存储数据，不同的partition可以位于不同的机器上，每台机器上都运行一个Kafka的进程Broker。</p>
<p><strong>为什么要对Topic下数据进行分区存储？</strong></p>
<p>1、commit log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了<strong>分布式存储</strong>，理论上一个topic可以处理任意数量的数据。</p>
<p>2、为了<strong>提高并行度</strong>。</p>
<h2 id="kafka集群实战"><a href="#kafka集群实战" class="headerlink" title="kafka集群实战"></a><strong>kafka集群实战</strong></h2><p>对于kafka来说，一个单独的broker意味着kafka集群中只有一个节点。要想增加kafka集群中的节点数量，只需要多启动几个broker实例即可。为了有更好的理解，现在我们在一台机器上同时启动三个broker实例。</p>
<p>首先，我们需要建立好其他2个broker的配置文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp config&#x2F;server.properties config&#x2F;server-1.properties</span><br><span class="line">cp config&#x2F;server.properties config&#x2F;server-2.properties</span><br></pre></td></tr></table></figure>

<p>配置文件的需要修改的内容分别如下：</p>
<p>config/server-1.properties:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#broker.id属性在kafka集群中必须要是唯一</span><br><span class="line">broker.id&#x3D;1</span><br><span class="line">#kafka部署的机器ip和提供服务的端口号</span><br><span class="line">#listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;192.168.65.60:9093 </span><br><span class="line">listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;:9093</span><br><span class="line">advertised.listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;120.27.71.186:9093</span><br><span class="line">#kafka的消息存储文件</span><br><span class="line">log.dir&#x3D;&#x2F;usr&#x2F;local&#x2F;data&#x2F;kafka-logs-1</span><br><span class="line">#kafka连接zookeeper的地址，要把多个kafka实例组成集群，对应连接的zookeeper必须相同</span><br><span class="line">zookeeper.connect&#x3D;120.27.71.186:2181</span><br></pre></td></tr></table></figure>

<p>config/server-2.properties:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#broker.id属性在kafka集群中必须要是唯一</span><br><span class="line">broker.id&#x3D;1</span><br><span class="line">#kafka部署的机器ip和提供服务的端口号</span><br><span class="line">#listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;192.168.65.60:9093 </span><br><span class="line">listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;:9093</span><br><span class="line">advertised.listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;120.27.71.186:9093</span><br><span class="line">#kafka的消息存储文件</span><br><span class="line">log.dir&#x3D;&#x2F;usr&#x2F;local&#x2F;data&#x2F;kafka-logs-1</span><br><span class="line">#kafka连接zookeeper的地址，要把多个kafka实例组成集群，对应连接的zookeeper必须相同</span><br><span class="line">zookeeper.connect&#x3D;120.27.71.186:2181</span><br></pre></td></tr></table></figure>

<p>目前我们已经有一个zookeeper实例和一个broker实例在运行了，现在我们只需要在启动2个broker实例即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-server-start.sh -daemon config&#x2F;server-1.properties</span><br><span class="line">bin&#x2F;kafka-server-start.sh -daemon config&#x2F;server-2.properties</span><br></pre></td></tr></table></figure>

<p><strong>查看zookeeper确认集群节点是否都注册成功：</strong></p>
<p><img src="/images/Kafka/Kafka_base08.png" alt="Kafka_base08"></p>
<p>现在我们创建一个新的topic，副本数设置为3，分区数设置为2：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --create --zookeeper 120.27.71.186:2181 --replication-factor 3 --partitions 2 --topic my-replicated-topic</span><br></pre></td></tr></table></figure>

<p><strong>查看下topic的情况</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --describe --zookeeper 120.27.71.186:2181 --topic my-replicated-topic</span><br></pre></td></tr></table></figure>

<p><img src="/images/Kafka/Kafka_base09.png" alt="Kafka_base09"></p>
<p>以下是输出内容的解释，第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息。</p>
<ul>
<li>leader节点负责给定partition的所有读写请求，同一个主题不同分区leader副本一般不一样(为了容灾)</li>
<li>replicas 表示某个partition在哪几个broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出。</li>
<li>isr 是replicas的一个子集，它只列出当前还存活着的，并且<strong>已同步备份</strong>了该partition的节点。</li>
</ul>
<p>现在我们向新建的 my-replicated-topic 中发送一些message，kafka集群可以加上所有kafka节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-producer.sh --broker-list 120.27.71.186:9092,120.27.71.186:9093,120.27.71.186:9094 --topic my-replicated-topic</span><br><span class="line">&gt;my test msg 1</span><br><span class="line">&gt;my test msg 2</span><br></pre></td></tr></table></figure>

<p>现在开始消费：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-consumer.sh --bootstrap-server 120.27.71.186:9092,120.27.71.186:9093,120.27.71.186:9094 --from-beginning --topic my-replicated-topic</span><br><span class="line">my test msg 1</span><br><span class="line">my test msg 2</span><br></pre></td></tr></table></figure>

<p>现在我们来测试我们容错性，因为broker1目前是my-replicated-topic的分区0的leader，所以我们要将其kill</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep server.properties</span><br><span class="line">kill 14776</span><br></pre></td></tr></table></figure>

<p>现在再执行命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --describe --zookeeper 120.27.71.186:2181 --topic my-replicated-topic</span><br></pre></td></tr></table></figure>

<p><img src="/images/Kafka/Kafka_base10.png" alt="Kafka_base10"></p>
<p>我们可以看到，分区0的leader节点已经变成了broker 0。要注意的是，在Isr中，已经没有了1号节点。leader的选举也是从ISR(in-sync replica)中进行的。</p>
<p>此时，我们依然可以 消费新消息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-consumer.sh --bootstrap-server 120.27.71.186:9092,120.27.71.186:9093,120.27.71.186:9094 --from-beginning --topic my-replicated-topic</span><br><span class="line">my test msg 1</span><br><span class="line">my test msg 2</span><br></pre></td></tr></table></figure>

<p>查看主题分区对应的leader信息：</p>
<p><img src="/images/Kafka/Kafka_base11.png" alt="Kafka_base11"></p>
<p><strong>kafka将很多集群关键信息记录在zookeeper里，保证自己的无状态，从而在水平扩容时非常方便。</strong></p>
<h2 id="集群消费"><a href="#集群消费" class="headerlink" title="集群消费"></a><strong>集群消费</strong></h2><p>log的partitions分布在kafka集群中不同的broker上，每个broker可以请求备份其他broker上partition上的数据。kafka集群支持配置一个partition备份的数量。</p>
<p>针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用。**leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多副本数据与消费的一致性)**。如果这个leader失效了，其中的一个follower将会自动的变成新的leader。</p>
<p><strong>Producers</strong></p>
<p>生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round-robin做简单的负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。</p>
<p><strong>Consumers</strong></p>
<p>传统的消息传递模式有2种：队列( queue) 和（publish-subscribe）</p>
<ul>
<li>queue模式：多个consumer从服务器中读取数据，消息只会到达一个consumer。</li>
<li>publish-subscribe模式：消息会被广播给所有的consumer。</li>
</ul>
<p>Kafka基于这2种模式提供了一种consumer的抽象概念：consumer group。</p>
<ul>
<li>queue模式：所有的consumer都位于同一个consumer group 下。</li>
<li>publish-subscribe模式：所有的consumer都有着自己唯一的consumer group。</li>
</ul>
<p><img src="/images/Kafka/Kafka_base12.png" alt="Kafka_base12">         </p>
<p> 上图说明：由2个broker组成的kafka集群，某个主题总共有4个partition(P0-P3)，分别位于不同的broker上。这个集群由2个Consumer Group消费， A有2个consumer instances ，B有4个。</p>
<p>通常一个topic会有几个consumer group，每个consumer group都是一个逻辑上的订阅者（ logical subscriber ）。每个consumer group由多个consumer instance组成，从而达到可扩展和容灾的功能。</p>
<p><strong>消费顺序</strong></p>
<p>一个partition同一个时刻在一个consumer group中只能有一个consumer instance在消费，从而保证消费顺序。</p>
<p><strong>consumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息。</strong></p>
<p>Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。</p>
<p>如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用。                 </p>
<h2 id="Java客户端访问Kafka"><a href="#Java客户端访问Kafka" class="headerlink" title="Java客户端访问Kafka"></a><strong>Java客户端访问Kafka</strong></h2><p>引入maven依赖</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">   &lt;groupId&gt;org.apache.kafka&lt;&#x2F;groupId&gt;</span><br><span class="line">   &lt;artifactId&gt;kafka-clients&lt;&#x2F;artifactId&gt;</span><br><span class="line">   &lt;version&gt;2.4.1&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<p>消息发送端代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">package com.tuling.kafka.kafkaDemo;</span><br><span class="line"></span><br><span class="line">import com.alibaba.fastjson.JSON;</span><br><span class="line">import org.apache.kafka.clients.producer.*;</span><br><span class="line">import org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line">import java.util.Properties;</span><br><span class="line">import java.util.concurrent.CountDownLatch;</span><br><span class="line">import java.util.concurrent.ExecutionException;</span><br><span class="line">import java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line">public class MsgProducer &#123;</span><br><span class="line">    private final static String TOPIC_NAME &#x3D; &quot;my-replicated-topic&quot;;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException, ExecutionException &#123;</span><br><span class="line">        Properties props &#x3D; new Properties();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;120.27.71.186:9092,120.27.71.186:9093,120.27.71.186:9094&quot;);</span><br><span class="line">         &#x2F;*</span><br><span class="line">         发出消息持久化机制参数</span><br><span class="line">        （1）acks&#x3D;0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息。</span><br><span class="line">        （2）acks&#x3D;1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入。就可以继续发送下一</span><br><span class="line">             条消息。这种情况下，如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失。</span><br><span class="line">        （3）acks&#x3D;-1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志，这种策略会保证</span><br><span class="line">            只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置。</span><br><span class="line">         *&#x2F;</span><br><span class="line">        &#x2F;*props.put(ProducerConfig.ACKS_CONFIG, &quot;1&quot;);</span><br><span class="line">         *&#x2F;&#x2F;*</span><br><span class="line">        发送失败会重试，默认重试间隔100ms，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，比如网络抖动，所以需要在</span><br><span class="line">        接收者那边做好消息接收的幂等性处理</span><br><span class="line">        *&#x2F;&#x2F;*</span><br><span class="line">        props.put(ProducerConfig.RETRIES_CONFIG, 3);</span><br><span class="line">        &#x2F;&#x2F;重试间隔设置</span><br><span class="line">        props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);</span><br><span class="line">        &#x2F;&#x2F;设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB</span><br><span class="line">        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);</span><br><span class="line">        *&#x2F;&#x2F;*</span><br><span class="line">        kafka本地线程会从缓冲区取数据，批量发送到broker，</span><br><span class="line">        设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去</span><br><span class="line">        *&#x2F;&#x2F;*</span><br><span class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);</span><br><span class="line">        *&#x2F;&#x2F;*</span><br><span class="line">        默认值是0，意思就是消息必须立即被发送，但这样会影响性能</span><br><span class="line">        一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去</span><br><span class="line">        如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长</span><br><span class="line">        *&#x2F;&#x2F;*</span><br><span class="line">        props.put(ProducerConfig.LINGER_MS_CONFIG, 10);*&#x2F;</span><br><span class="line">        &#x2F;&#x2F;把发送的key从字符串序列化为字节数组</span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        &#x2F;&#x2F;把发送消息value从字符串序列化为字节数组</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        Producer&lt;String, String&gt; producer &#x3D; new KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        int msgNum &#x3D; 5;</span><br><span class="line">        final CountDownLatch countDownLatch &#x3D; new CountDownLatch(msgNum);</span><br><span class="line">        for (int i &#x3D; 1; i &lt;&#x3D; msgNum; i++) &#123;</span><br><span class="line">            Order order &#x3D; new Order(i, 100 + i, 1, 1000.00);</span><br><span class="line">            &#x2F;&#x2F;指定发送分区</span><br><span class="line">            &#x2F;*ProducerRecord&lt;String, String&gt; producerRecord &#x3D; new ProducerRecord&lt;String, String&gt;(TOPIC_NAME</span><br><span class="line">                    , 0, order.getOrderId().toString(), JSON.toJSONString(order));*&#x2F;</span><br><span class="line">            &#x2F;&#x2F;未指定发送分区，具体发送的分区计算公式：hash(key)%partitionNum</span><br><span class="line">            ProducerRecord&lt;String, String&gt; producerRecord &#x3D; new ProducerRecord&lt;String, String&gt;(TOPIC_NAME</span><br><span class="line">                    , order.getOrderId().toString(), JSON.toJSONString(order));</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F;等待消息发送成功的同步阻塞方法</span><br><span class="line">            &#x2F;*RecordMetadata metadata &#x3D; producer.send(producerRecord).get();</span><br><span class="line">            System.out.println(&quot;同步方式发送消息结果：&quot; + &quot;topic-&quot; + metadata.topic() + &quot;|partition-&quot;</span><br><span class="line">                    + metadata.partition() + &quot;|offset-&quot; + metadata.offset());*&#x2F;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F;异步回调方式发送消息</span><br><span class="line">            producer.send(producerRecord, new Callback() &#123;</span><br><span class="line">                public void onCompletion(RecordMetadata metadata, Exception exception) &#123;</span><br><span class="line">                    if (exception !&#x3D; null) &#123;</span><br><span class="line">                        System.err.println(&quot;发送消息失败：&quot; + exception.getStackTrace());</span><br><span class="line"></span><br><span class="line">                    &#125;</span><br><span class="line">                    if (metadata !&#x3D; null) &#123;</span><br><span class="line">                        System.out.println(&quot;异步方式发送消息结果：&quot; + &quot;topic-&quot; + metadata.topic() + &quot;|partition-&quot;</span><br><span class="line">                                + metadata.partition() + &quot;|offset-&quot; + metadata.offset());</span><br><span class="line">                    &#125;</span><br><span class="line">                    countDownLatch.countDown();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F;送积分 TODO</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        countDownLatch.await(5, TimeUnit.SECONDS);</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>消息接收端代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line">package com.tuling.kafka.kafkaDemo;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line">import org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line">import org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line">import org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line">import org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line">import java.time.Duration;</span><br><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">public class MsgConsumer &#123;</span><br><span class="line">    private final static String TOPIC_NAME &#x3D; &quot;my-replicated-topic&quot;;</span><br><span class="line">    private final static String CONSUMER_GROUP_NAME &#x3D; &quot;testGroup&quot;;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Properties props &#x3D; new Properties();</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;120.27.71.186:9092,120.27.71.186:9093,120.27.71.186:9094&quot;);</span><br><span class="line">        &#x2F;&#x2F; 消费分组名</span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);</span><br><span class="line">        &#x2F;&#x2F; 是否自动提交offset，默认就是true</span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;true&quot;);</span><br><span class="line">        &#x2F;&#x2F; 自动提交offset的间隔时间</span><br><span class="line">        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;1000&quot;);</span><br><span class="line">        &#x2F;&#x2F;props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;);</span><br><span class="line">        &#x2F;*</span><br><span class="line">        当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费</span><br><span class="line">        latest(默认) ：只消费自己启动之后发送到主题的消息</span><br><span class="line">        earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于consumer.seekToBeginning(每次都从头开始消费)</span><br><span class="line">        *&#x2F;</span><br><span class="line">        &#x2F;&#x2F;props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);</span><br><span class="line">      &#x2F;*</span><br><span class="line">      consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将</span><br><span class="line">      rebalance方案下发给consumer，这个时间可以稍微短一点</span><br><span class="line">      *&#x2F;</span><br><span class="line">        props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);</span><br><span class="line">        &#x2F;*</span><br><span class="line">        服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，</span><br><span class="line">        对应的Partition也会被重新分配给其他consumer，默认是10秒</span><br><span class="line">        *&#x2F;</span><br><span class="line">        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);</span><br><span class="line">        &#x2F;&#x2F;一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点</span><br><span class="line">        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);</span><br><span class="line">        &#x2F;*</span><br><span class="line">        如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，</span><br><span class="line">        会将其踢出消费组，将分区分配给别的consumer消费</span><br><span class="line">        *&#x2F;</span><br><span class="line">        props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer &#x3D; new KafkaConsumer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        consumer.subscribe(Arrays.asList(TOPIC_NAME));</span><br><span class="line">        &#x2F;&#x2F; 消费指定分区</span><br><span class="line">        &#x2F;&#x2F;consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;消息回溯消费</span><br><span class="line">        &#x2F;*consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));</span><br><span class="line">        consumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));*&#x2F;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;指定offset消费</span><br><span class="line">        &#x2F;*consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));</span><br><span class="line">        consumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);*&#x2F;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;从指定时间点开始消费</span><br><span class="line">        &#x2F;*List&lt;PartitionInfo&gt; topicPartitions &#x3D; consumer.partitionsFor(TOPIC_NAME);</span><br><span class="line">        &#x2F;&#x2F;从1小时前开始消费</span><br><span class="line">        long fetchDataTime &#x3D; new Date().getTime() - 1000 * 60 * 60;</span><br><span class="line">        Map&lt;TopicPartition, Long&gt; map &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        for (PartitionInfo par : topicPartitions) &#123;</span><br><span class="line">            map.put(new TopicPartition(topicName, par.partition()), fetchDataTime);</span><br><span class="line">        &#125;</span><br><span class="line">        Map&lt;TopicPartition, OffsetAndTimestamp&gt; parMap &#x3D; consumer.offsetsForTimes(map);</span><br><span class="line">        for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : parMap.entrySet()) &#123;</span><br><span class="line">            TopicPartition key &#x3D; entry.getKey();</span><br><span class="line">            OffsetAndTimestamp value &#x3D; entry.getValue();</span><br><span class="line">            if (key &#x3D;&#x3D; null || value &#x3D;&#x3D; null) continue;</span><br><span class="line">            Long offset &#x3D; value.offset();</span><br><span class="line">            System.out.println(&quot;partition-&quot; + key.partition() + &quot;|offset-&quot; + offset);</span><br><span class="line">            System.out.println();</span><br><span class="line">            &#x2F;&#x2F;根据消费里的timestamp确定offset</span><br><span class="line">            if (value !&#x3D; null) &#123;</span><br><span class="line">                consumer.assign(Arrays.asList(key));</span><br><span class="line">                consumer.seek(key, offset);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;*&#x2F;</span><br><span class="line"></span><br><span class="line">        while (true) &#123;</span><br><span class="line">            &#x2F;*</span><br><span class="line">             * poll() API 是拉取消息的长轮询</span><br><span class="line">             *&#x2F;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(Duration.ofMillis(1000));</span><br><span class="line">            for (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(&quot;收到消息：partition &#x3D; %d,offset &#x3D; %d, key &#x3D; %s, value &#x3D; %s%n&quot;, record.partition(),</span><br><span class="line">                        record.offset(), record.key(), record.value());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            &#x2F;*if (records.count() &gt; 0) &#123;</span><br><span class="line">                &#x2F;&#x2F; 手动同步提交offset，当前线程会阻塞直到offset提交成功</span><br><span class="line">                &#x2F;&#x2F; 一般使用同步提交，因为提交之后一般也没有什么逻辑代码了</span><br><span class="line">                consumer.commitSync();</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑</span><br><span class="line">                consumer.commitAsync(new OffsetCommitCallback() &#123;</span><br><span class="line">                    @Override</span><br><span class="line">                    public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) &#123;</span><br><span class="line">                        if (exception !&#x3D; null) &#123;</span><br><span class="line">                            System.err.println(&quot;Commit failed for &quot; + offsets);</span><br><span class="line">                            System.err.println(&quot;Commit failed exception: &quot; + exception.getStackTrace());</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line">            &#125;*&#x2F;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Spring-Boot整合Kafka"><a href="#Spring-Boot整合Kafka" class="headerlink" title="Spring Boot整合Kafka"></a><strong>Spring Boot整合Kafka</strong></h2><p>引入spring boot kafka依赖，详见项目实例：spring-boot-kafka</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.kafka&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-kafka&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<p>application.yml配置如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">server:</span><br><span class="line">  port: 8080</span><br><span class="line"></span><br><span class="line">spring:</span><br><span class="line">  kafka:</span><br><span class="line">    bootstrap-servers: 120.27.71.186:9092,120.27.71.186:9093,120.27.71.186:9094</span><br><span class="line">    producer: # 生产者</span><br><span class="line">      retries: 3 # 设置大于0的值，则客户端会将发送失败的记录重新发送</span><br><span class="line">      batch-size: 16384</span><br><span class="line">      buffer-memory: 33554432</span><br><span class="line">      acks: 1</span><br><span class="line">      # 指定消息key和消息体的编解码方式</span><br><span class="line">      key-serializer: org.apache.kafka.common.serialization.StringSerializer</span><br><span class="line">      value-serializer: org.apache.kafka.common.serialization.StringSerializer</span><br><span class="line">    consumer:</span><br><span class="line">      group-id: default-group</span><br><span class="line">      enable-auto-commit: false</span><br><span class="line">      auto-offset-reset: earliest</span><br><span class="line">      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer</span><br><span class="line">      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer</span><br><span class="line">    listener:</span><br><span class="line">      # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交</span><br><span class="line">      # RECORD</span><br><span class="line">      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交</span><br><span class="line">      # BATCH</span><br><span class="line">      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交</span><br><span class="line">      # TIME</span><br><span class="line">      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交</span><br><span class="line">      # COUNT</span><br><span class="line">      # TIME |　COUNT　有一个条件满足时提交</span><br><span class="line">      # COUNT_TIME</span><br><span class="line">      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交</span><br><span class="line">      # MANUAL</span><br><span class="line">      # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种</span><br><span class="line">      # MANUAL_IMMEDIATE</span><br><span class="line">      ack-mode: manual_immediate</span><br></pre></td></tr></table></figure>

<p>发送者代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">package com.kafka;</span><br><span class="line"></span><br><span class="line">import org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line">import org.springframework.kafka.core.KafkaTemplate;</span><br><span class="line">import org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line">import org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line">@RestController</span><br><span class="line">public class KafkaController &#123;</span><br><span class="line"></span><br><span class="line">    private final static String TOPIC_NAME &#x3D; &quot;my-replicated-topic&quot;;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;</span><br><span class="line"></span><br><span class="line">    @RequestMapping(&quot;&#x2F;send&quot;)</span><br><span class="line">    public void send() &#123;</span><br><span class="line">        kafkaTemplate.send(TOPIC_NAME, 0, &quot;key&quot;, &quot;this is a msg&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>消费者代码：           </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">package com.kafka; </span><br><span class="line">import org.apache.kafka.clients.consumer.ConsumerRecord; </span><br><span class="line">import org.springframework.kafka.annotation.KafkaListener; </span><br><span class="line">import org.springframework.kafka.support.Acknowledgment; </span><br><span class="line">import org.springframework.stereotype.Component; </span><br><span class="line">@Component</span><br><span class="line">public class MyConsumer &#123; </span><br><span class="line">    </span><br><span class="line">     &#x2F;**</span><br><span class="line">      * @KafkaListener(groupId &#x3D; &quot;testGroup&quot;, topicPartitions &#x3D; &#123;</span><br><span class="line">      * @TopicPartition(topic &#x3D; &quot;topic1&quot;, partitions &#x3D; &#123;&quot;0&quot;, &quot;1&quot;&#125;),</span><br><span class="line">      * @TopicPartition(topic &#x3D; &quot;topic2&quot;, partitions &#x3D; &quot;0&quot;,</span><br><span class="line">      * partitionOffsets &#x3D; @PartitionOffset(partition &#x3D; &quot;1&quot;, initialOffset &#x3D; &quot;100&quot;))</span><br><span class="line">      * &#125;,concurrency &#x3D; &quot;6&quot;)</span><br><span class="line">      * &#x2F;&#x2F;concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数</span><br><span class="line">      * @param record</span><br><span class="line">      *&#x2F;</span><br><span class="line">     @KafkaListener(topics &#x3D; &quot;my‐replicated‐topic&quot;,groupId &#x3D; &quot;zhugeGroup&quot;)</span><br><span class="line">     public void listenZhugeGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123;</span><br><span class="line">         String value &#x3D; record.value();</span><br><span class="line">         System.out.println(value);</span><br><span class="line">         System.out.println(record);</span><br><span class="line">        &#x2F;&#x2F;手动提交offset</span><br><span class="line">         ack.acknowledge();</span><br><span class="line">      &#125; </span><br><span class="line">       </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">     &#x2F;*&#x2F;&#x2F;配置多个消费组 </span><br><span class="line">     @KafkaListener(topics &#x3D; &quot;my‐replicated‐topic&quot;,groupId &#x3D; &quot;tulingGroup&quot;) </span><br><span class="line">     public void listenTulingGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123; </span><br><span class="line">         String value &#x3D; record.value(); </span><br><span class="line">         System.out.println(value); </span><br><span class="line">         System.out.println(record); </span><br><span class="line">         ack.acknowledge(); </span><br><span class="line">     &#125;*&#x2F; </span><br><span class="line">        </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/kafka/" rel="tag"># kafka</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/06/01/Zookeeper/2022-06-01%20zookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEZAB%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/" rel="prev" title="zookeeper分布式一致性协议ZAB源码剖析">
      <i class="fa fa-chevron-left"></i> zookeeper分布式一致性协议ZAB源码剖析
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/06/07/Kafka/2022-06-07%20kafka%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/" rel="next" title="kafka设计原理详解">
      kafka设计原理详解 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">1.</span> <span class="nav-text">Kafka的使用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">2.</span> <span class="nav-text">Kafka基本概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="nav-number">3.</span> <span class="nav-text">kafka基本使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85"><span class="nav-number">3.1.</span> <span class="nav-text">第一步：下载安装包</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE"><span class="nav-number">3.2.</span> <span class="nav-text">第二步：修改配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.3.</span> <span class="nav-text">第三步：启动服务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E5%88%9B%E5%BB%BA%E4%B8%BB%E9%A2%98"><span class="nav-number">3.4.</span> <span class="nav-text">第四步：创建主题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E6%AD%A5%EF%BC%9A%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF"><span class="nav-number">3.5.</span> <span class="nav-text">第五步：发送消息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%85%AD%E6%AD%A5%EF%BC%9A%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF"><span class="nav-number">3.6.</span> <span class="nav-text">第六步：消费消息</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E9%A2%98Topic%E5%92%8C%E6%B6%88%E6%81%AF%E6%97%A5%E5%BF%97Log"><span class="nav-number">4.</span> <span class="nav-text">主题Topic和消息日志Log</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka%E9%9B%86%E7%BE%A4%E5%AE%9E%E6%88%98"><span class="nav-number">5.</span> <span class="nav-text">kafka集群实战</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E6%B6%88%E8%B4%B9"><span class="nav-number">6.</span> <span class="nav-text">集群消费</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%AE%BF%E9%97%AEKafka"><span class="nav-number">7.</span> <span class="nav-text">Java客户端访问Kafka</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spring-Boot%E6%95%B4%E5%90%88Kafka"><span class="nav-number">8.</span> <span class="nav-text">Spring Boot整合Kafka</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="QingSong"
      src="/images/avatar/avatar.png">
  <p class="site-author-name" itemprop="name">QingSong</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">183</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">QingSong</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
